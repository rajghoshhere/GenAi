{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e5acedec-a607-49c5-8730-1cb04faff8d9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Step 1: Install Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e5328663-defe-40f8-ae84-14c0aa53f49b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "%pip install numpy==1.24.4 --no-cache-dir\n",
    "%pip install --force-reinstall --no-deps langchain langchain-community langchain-openai\n",
    "%pip install databricks-sdk\n",
    "%pip install -U duckduckgo-search\n",
    "%pip install langchain-core\n",
    "%pip install langchain-text-splitters\n",
    "%pip install aiohttp\n",
    "dbutils.library.restartPython()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "20cf7b0b-c3e7-4e3f-9fed-a94b1861c3b5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install wikipedia\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "03fdcc56-7f0b-442d-83d4-729e0aa45c24",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatDatabricks\n",
    "from langchain.agents import Tool, AgentExecutor, create_structured_chat_agent\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "from langchain.agents.react.agent import create_react_agent\n",
    "import random\n",
    "\n",
    "llm = ChatDatabricks(\n",
    "    endpoint=\"any databrick endpoint\",\n",
    "    temperature=0.7,\n",
    "    max_tokens=1000\n",
    ")\n",
    "\n",
    "import os\n",
    "os.environ[\"TAVILY_API_KEY\"] = \"Your Tavily API Key\"\n",
    "# Tools\n",
    "wiki = WikipediaAPIWrapper()\n",
    "#duck duck works well, if you search simultenously, it gives error\n",
    "#search = DuckDuckGoSearchRun()\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "search = TavilySearchResults()\n",
    "\n",
    "\n",
    "def generate_joke(topic: str) -> str:\n",
    "    prompt = f\"Tell me a short, funny joke about {topic}.\"\n",
    "    return llm([HumanMessage(content=prompt)])\n",
    "\n",
    "tools = [\n",
    "    Tool(name=\"Wikipedia\", func=wiki.run, description=\"Get summary from Wikipedia\"),\n",
    "    Tool(name=\"YouTube Search\", func=lambda q: search.run(f\"{q} site:youtube.com\"), description=\"Find YouTube videos\"),\n",
    "    Tool(name=\"Joke Generator\", func=generate_joke,\n",
    "    description=\"Generates a funny AI-generated joke about the given topic\"\n",
    ")\n",
    "]\n",
    "\n",
    "tool_names = [tool.name for tool in tools]\n",
    "\n",
    "# Prompt\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\n",
    "     \"You are a helpful research assistant using ReAct framework.\\n\"\n",
    "     \"You have access to the following tools:\\n\\n{tools}\\n\\n\"\n",
    "     \"When you answer, use the following format strictly:\\n\\n\"\n",
    "     \"Question: the input question you must answer\\n\"\n",
    "     \"Thought: you should always think about what to do\\n\"\n",
    "     \"Action: the action to take, must be one of [{tool_names}]\\n\"\n",
    "     \"Action Input: the input to the action\\n\"\n",
    "     \"Observation: the result of the action\\n\"\n",
    "     \"...(Repeat Thought/Action/Action Input/Observation as needed)\\n\"\n",
    "     \"Final Answer: the final answer to the original question\\n\"),\n",
    "    (\"human\", \"{input}\"),\n",
    "    (\"ai\", \"Thought: {agent_scratchpad}\")\n",
    "])\n",
    "prompt.input_variables = [\"input\", \"tool_names\", \"agent_scratchpad\", \"tools\"]\n",
    "\n",
    "# Agent & executor\n",
    "agent = create_react_agent(llm, tools, prompt)\n",
    "\n",
    "agent_executor = AgentExecutor.from_agent_and_tools(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True\n",
    ")\n",
    "from langchain.schema.messages import AIMessage, HumanMessage, ToolMessage\n",
    "agent_scratchpad = [\n",
    "    AIMessage(content=\"I'll search Wikipedia.\"),\n",
    "    ToolMessage(\n",
    "        tool_call_id=\"tool-1\",\n",
    "        tool_name=\"Wikipedia\",\n",
    "        content=\"LangChain is a framework to build apps using LLMs.\"\n",
    "    ),\n",
    "    AIMessage(content=f\"As requested, here's a joke about topic\"),\n",
    "    ToolMessage(\n",
    "        tool_call_id=\"tool-2\",\n",
    "        tool_name=\"Joke Generator\",\n",
    "        content=\"Here's a joke about {topic}:\"\n",
    "    )\n",
    "]\n",
    "#agent_scratchpad.append(AIMessage(content=\"I'll search Wikipedia.\"))\n",
    "#agent_scratchpad.append(ToolMessage(tool_call_id=\"tool-1\",tool_name=wiki, content=\"LangChain is a framework to build apps using LLMs.\"))\n",
    "\n",
    "# Function\n",
    "def run_topic_agent(topic: str):\n",
    "    query = f\"\"\"\n",
    "    I want to learn about '{topic}'.\n",
    "    1. Give me a summary from Wikipedia.\n",
    "    2. Recommend a YouTube video to watch on this topic.\n",
    "    3. End with a very funny joke about '{topic}'.\n",
    "    \"\"\"\n",
    "    response = agent_executor.invoke({\n",
    "        \"input\": query,\n",
    "        \"agent_scratchpad\": agent_scratchpad,\n",
    "        \"tool_names\": tool_names\n",
    "    })\n",
    "    print(\"\\nðŸ“Œ Final Response:\\n\", response[\"output\"])\n",
    "\n",
    "# Run it\n",
    "run_topic_agent(\"Chiceken, leg piece\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "177130ee-7bff-43b6-b850-8abfd8fcd61c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Run Query"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Agentic AI- MultitoolResearchAgent",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
